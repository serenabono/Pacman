{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQoIglmxuL7O"
   },
   "source": [
    "ssh -t seb400@o2.hms.harvard.edu -L 8886:localhost:8886 ssh $NODE_ID -L 8886:localhost:8886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 6751,
     "status": "ok",
     "timestamp": 1702832531755,
     "user": {
      "displayName": "serena bono",
      "userId": "12077246040538626691"
     },
     "user_tz": -60
    },
    "id": "xcEQb9CuuL7Q",
    "outputId": "3a59079a-5ccc-468c-9aab-7b253e8d9e5d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import plotly\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "import plotly.express as px\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36073,
     "status": "ok",
     "timestamp": 1702832572194,
     "user": {
      "displayName": "serena bono",
      "userId": "12077246040538626691"
     },
     "user_tz": -60
    },
    "id": "-qLfiVjLuL7R",
    "outputId": "1481e487-32b1-42fa-c710-f98d089c462b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "data = {}\n",
    "name = {}\n",
    "for path, directories, files in os.walk('.'):\n",
    "    if \"_trial_\" in path:\n",
    "        print(path)\n",
    "        for file in files:\n",
    "            if \"_epoch\" not in file:\n",
    "                continue\n",
    "            if \"json\" in file:\n",
    "                agent = path.split(\"_\")[-6]\n",
    "                exploration_strategy = path.split(\"_\")[-5]\n",
    "                grid = path.split(\"_\")[-4]\n",
    "                bar = \"_\".join(path.split(\"_\")[-3:-1])\n",
    "                noise = \"\".join(path.split(\"_\")[-1])\n",
    "                if agent not in data:\n",
    "                    data[agent] = {}\n",
    "                    name[agent] = {}\n",
    "                if exploration_strategy not in data[agent]:\n",
    "                    data[agent][exploration_strategy] = {}\n",
    "                    name[agent][exploration_strategy] = {}\n",
    "                if grid not in data[agent][exploration_strategy]:\n",
    "                    data[agent][exploration_strategy][grid] = {}\n",
    "                    name[agent][exploration_strategy][grid] = {}\n",
    "                if bar not in data[agent][exploration_strategy][grid]:\n",
    "                    data[agent][exploration_strategy][grid][bar] = {}\n",
    "                    name[agent][exploration_strategy][grid][bar] = {}\n",
    "                if noise not in data[agent][exploration_strategy][grid][bar]:\n",
    "                    data[agent][exploration_strategy][grid][bar][noise] = []\n",
    "                    name[agent][exploration_strategy][grid][bar][noise] = []\n",
    "                with open(os.path.join(path, file)) as f:\n",
    "                    #print(f\"reading filename {os.path.join(path, file)}\\n\")\n",
    "                    data[agent][exploration_strategy][grid][bar][noise].append(json.load(f))\n",
    "                    train_epoch = file.split(\"-\")[-1].replace(rf\"train0_\",\"\").replace(\".json\",\"\")\n",
    "                    name[agent][exploration_strategy][grid][bar][noise].append(\"_\".join(path.split(\"_\")[-4:]) +\"_\"+ train_epoch)\n",
    "\n",
    "                    n = \"_\".join(path.split(\"_\")[-4:]) +\"_\"+ train_epoch\n",
    "                    print(f\"saving {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name['SarsaAgent']['Boltzmann']['v2']['DirectionalGhost_{\"index\":1,\"prob\":0.3}'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMPfaMYSuL7S"
   },
   "outputs": [],
   "source": [
    "# generate GIFS\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "def create_gif(input_folder, output_file, file_extension=\".png\", duration=1.0):\n",
    "    images = []\n",
    "\n",
    "    # Get file names and sort them based on the number of epochs\n",
    "    idxs = sorted(range(len(name[agent][exploration_strategy][somegrid][someghost][somenoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someghost][somenoise][x].split('_')[-2]))\n",
    "    for filename in np.asarray(name[agent][exploration_strategy][somegrid][someghost][somenoise])[idxs]:\n",
    "        filepath = os.path.join(input_folder, filename + \".png\")\n",
    "        images.append(imageio.imread(filepath))\n",
    "\n",
    "    # Save the images as a GIF with the specified duration\n",
    "    imageio.mimsave(output_file, images, duration=duration)\n",
    "def nanargmax_with_default(series):\n",
    "    return 0 if series.isna().all() else np.nanargmax(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQLmoqvuuL7S"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "import imageio\n",
    "import shutil\n",
    "\n",
    "cmap = mpl.colormaps.get_cmap('binary_r')  # viridis is the default colormap for imshow\n",
    "cmap.set_bad(color ='red', alpha=0.1)\n",
    "\n",
    "\n",
    "def generate_gifs_inner_explored_states(folder,subfolder,agent, exploration_strategy, somegrid, someghost, somenoise, someotherghost, someothernoise):\n",
    "    print(somegrid, someghost, somenoise)\n",
    "    print(f\"len: {len(data[agent][exploration_strategy][somegrid][someghost][somenoise])}\")\n",
    "    idxs = sorted(range(len(name[agent][exploration_strategy][somegrid][someghost][somenoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someghost][somenoise][x].split('_')[-2]))\n",
    "    evolution_game = np.asarray(data[agent][exploration_strategy][somegrid][someghost][somenoise])[idxs]\n",
    "    idxs_o = sorted_indices = sorted(range(len(name[agent][exploration_strategy][somegrid][someotherghost][someothernoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someotherghost][someothernoise][x].split('_')[-2]))\n",
    "    evolution_game_other = np.asarray(data[agent][exploration_strategy][somegrid][someotherghost][someothernoise])[idxs_o]\n",
    "\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[-1]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[-1]).sort_index()\n",
    "    all_columns = action_pd_noise.columns.intersection(action_pd_no_noise.columns)\n",
    "    merge_common = pd.concat([action_pd_noise[all_columns], action_pd_no_noise[all_columns]], axis=0, keys=['action_pd_no_noise', 'action_pd_noise'])[all_columns]\n",
    "    merge_common.index = merge_common.index.droplevel()\n",
    "    final_column = np.argsort(merge_common.iloc[:4,:].apply(nanargmax_with_default).to_numpy() == merge_common.iloc[4:,:].apply(nanargmax_with_default).to_numpy())[::-1]\n",
    "    common_nan_mask = np.isnan(merge_common.iloc[:4,:].values) & np.isnan(merge_common.iloc[4:,:].values)\n",
    "    column_mask = np.all(common_nan_mask, axis=0)[final_column]\n",
    "    masked_data_terminal = np.ma.masked_array(common_nan_mask, mask=np.repeat(column_mask.reshape(1,-1), 4, axis=0))\n",
    "    all_columns = all_columns[final_column]\n",
    "    directory_path = f\"{folder}/{subfolder}\"\n",
    "\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "    else:\n",
    "        print(f\"Found preexisting {directory_path}. Removing...\")\n",
    "        shutil.rmtree(directory_path)\n",
    "        os.makedirs(directory_path)\n",
    "\n",
    "    for sortex_idx in range(len(data[agent][exploration_strategy][somegrid][someghost][somenoise])):\n",
    "\n",
    "        action_pd_no_noise = pd.DataFrame(evolution_game[sortex_idx]).sort_index()\n",
    "        action_pd_noise = pd.DataFrame(evolution_game_other[sortex_idx]).sort_index()\n",
    "\n",
    "        common_columns = action_pd_no_noise.columns.intersection(action_pd_noise.columns)\n",
    "        action_pd_no_noise_common = pd.concat([action_pd_no_noise[common_columns],pd.DataFrame(columns=list(set(all_columns) - set(common_columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "        action_pd_noise_common = pd.concat([action_pd_noise[common_columns],pd.DataFrame(columns=list(set(all_columns) - set(common_columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "\n",
    "        merge_common = pd.concat([action_pd_no_noise_common, action_pd_noise_common], axis=0, keys=['action_pd_no_noise', 'action_pd_noise'])[all_columns]\n",
    "        a = pd.DataFrame(merge_common.iloc[:4,:].apply(nanargmax_with_default).to_numpy() == merge_common.iloc[4:,:].apply(nanargmax_with_default).to_numpy(), index=all_columns).values.astype(float)\n",
    "        a[column_mask] = np.nan\n",
    "        plt.imshow(a.T, aspect=\"auto\", cmap=cmap)\n",
    "        plt.colorbar()\n",
    "        plt.savefig(f\"{folder}/{subfolder}/{name[agent][exploration_strategy][somegrid][someghost][somenoise][idxs[sortex_idx]]}.png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON SEMANTIC NOISE\n",
    "#grid\n",
    "somegrid_l = ['v2','v3','v4']\n",
    "someagent_l = ['SarsaAgent']\n",
    "someexploration_strategy_l = ['Boltzmann']\n",
    "#training env\n",
    "someghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}','DirectionalGhost_{\"index\":1,\"prob\":0.3}','DirectionalGhost_{\"index\":1,\"prob\":0.6}']\n",
    "somenoise_l = ['{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}']\n",
    "#testing env\n",
    "someotherghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}','DirectionalGhost_{\"index\":1,\"prob\":0.3}','DirectionalGhost_{\"index\":1,\"prob\":0.6}']\n",
    "someothernoise_l = ['{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}']\n",
    "\n",
    "for someagent in someagent_l:\n",
    "    for someexploration_strategy in someexploration_strategy_l:\n",
    "        for somegrid in somegrid_l:\n",
    "            for someghost, somenoise, someotherghost, someothernoise in zip(someghost_l, somenoise_l, someotherghost_l, someothernoise_l):\n",
    "                print(f\"Generating gifs for {somegrid}, {someghost}, {somenoise}, {someotherghost}, {someothernoise}\")\n",
    "                folder = f'_trial_learnability_{someagent}_{someexploration_strategy}_' + re.sub(r\"_training_agent_\\d+_epoch\", \"\", np.asarray(name[agent][exploration_strategy][somegrid][someghost][somenoise])[0])\n",
    "                subfolder = f\"common_{somegrid}_{someghost}_{somenoise}_{someotherghost}_{someothernoise}\"\n",
    "                print(f\"folder: {folder}\")\n",
    "                generate_gifs_inner_explored_states(folder,subfolder,someagent, someexploration_strategy, somegrid, someghost, somenoise, someotherghost, someothernoise)\n",
    "                input_folder = f\"{folder}/{subfolder}/\"\n",
    "                output_file = f\"{folder}/{subfolder}/{subfolder}.gif\"\n",
    "                create_gif(input_folder, output_file, duration=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyGq1NMMuL7T",
    "outputId": "41a4cc04-9fc8-40b5-9173-38c320e968fe"
   },
   "outputs": [],
   "source": [
    "# SEMANTIC NOISE\n",
    "#grid\n",
    "somegrid_l = ['v2','v3','v4']\n",
    "\n",
    "someagent_l = ['SarsaAgent']\n",
    "someexploration_strategy_l = ['Boltzmann']\n",
    "#training env\n",
    "someghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}']\n",
    "somenoise_l = ['{\"mean\":0,\"std\":0}']\n",
    "#testing env\n",
    "someotherghost_l = ['RandomGhostTeleportingNearWalls_{\"index\":1,\"prob\":{}}']\n",
    "someothernoise_l =  ['{\"mean\":0,\"std\":0}']\n",
    "\n",
    "for someagent in someagent_l:\n",
    "    for someexploration_strategy in someexploration_strategy_l:\n",
    "        for somegrid in somegrid_l:\n",
    "            for someghost, somenoise, someotherghost, someothernoise in zip(someghost_l, somenoise_l, someotherghost_l, someothernoise_l):\n",
    "                print(f\"Generating gifs for {somegrid}, {someghost}, {somenoise}, {someotherghost}, {someothernoise}\")\n",
    "                folder = f'_trial_learnability_{someagent}_{someexploration_strategy}_' + re.sub(r\"_training_agent_\\d+_epoch\", \"\", np.asarray(name[agent][exploration_strategy][somegrid][someghost][somenoise])[0])\n",
    "                subfolder = f\"common_{somegrid}_{someghost}_{somenoise}_{someotherghost}_{someothernoise}\"\n",
    "                print(f\"folder: {folder}\")\n",
    "                generate_gifs_inner_explored_states(folder,subfolder, someagent, someexploration_strategy, somegrid, someghost, somenoise, someotherghost, someothernoise)\n",
    "                input_folder = f\"{folder}/{subfolder}/\"\n",
    "                output_file = f\"{folder}/{subfolder}/{subfolder}.gif\"\n",
    "                create_gif(input_folder, output_file, duration=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[agent][exploration_strategy]['v2']['RandomGhost_{\"index\":1,\"prob\":{}}'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnwHU6ChuL7U",
    "outputId": "73851642-3fb1-4f4a-a913-2f1db4f5a61a"
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import tqdm\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "cmap = mpl.colormaps.get_cmap('binary')  # viridis is the default colormap for imshow\n",
    "\n",
    "cmap.set_under(color ='blue')  # Set the color for values below vmin to blue\n",
    "cmap.set_over(color ='red')\n",
    "cmap.set_bad(color ='green', alpha=0.1)\n",
    "\n",
    "def generategifs_occupancy(folder,subfolder,agent, exploration_strategy, somegrid, someghost, somenoise, someotherghost, someothernoise):\n",
    "    print(somegrid, someghost, somenoise)\n",
    "    print(f\"len: {len(data[agent][exploration_strategy][somegrid][someghost][somenoise])}\")\n",
    "    idxs = sorted(range(len(name[agent][exploration_strategy][somegrid][someghost][somenoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someghost][somenoise][x].split('_')[-2]))\n",
    "    evolution_game = np.asarray(data[agent][exploration_strategy][somegrid][someghost][somenoise])[idxs]\n",
    "    idxs_o = sorted_indices = sorted(range(len(name[agent][exploration_strategy][somegrid][someotherghost][someothernoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someotherghost][someothernoise][x].split('_')[-2]))\n",
    "    evolution_game_other = np.asarray(data[agent][exploration_strategy][somegrid][someotherghost][someothernoise])[idxs_o]\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[-1]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[-1]).sort_index()\n",
    "    all_columns = pd.merge(action_pd_no_noise.fillna(np.nan).astype(float), action_pd_noise.fillna(np.nan).astype(float), how=\"outer\").columns\n",
    "    action_pd_no_noise_complete = pd.concat([action_pd_no_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_no_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    action_pd_noise_complete = pd.concat([action_pd_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    common_nan_mask = np.isnan(action_pd_no_noise_complete.values) & np.isnan(action_pd_noise_complete.values)\n",
    "    column_mask = np.all(common_nan_mask, axis=0)\n",
    "    masked_data_terminal = np.ma.masked_array(common_nan_mask, mask=np.repeat(column_mask.reshape(1,-1), 4, axis=0))\n",
    "    \n",
    "    for sortex_idx in range(len(data[agent][exploration_strategy][somegrid][someghost][somenoise])):\n",
    "        #fig, ax = plt.subplots(1,1, figsize=(27,27))\n",
    "        action_pd_no_noise = pd.DataFrame(evolution_game[sortex_idx]).sort_index()\n",
    "        action_pd_noise = pd.DataFrame(evolution_game_other[sortex_idx]).sort_index()\n",
    "    \n",
    "        action_pd_no_noise_complete = pd.concat([action_pd_no_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_no_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "        action_pd_noise_complete = pd.concat([action_pd_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "        common_nan_mask = np.isnan(action_pd_no_noise_complete.values) & np.isnan(action_pd_noise_complete.values)\n",
    "        action_pd_noise_nan_mask = np.isnan(action_pd_noise_complete.values) & ~np.isnan(action_pd_no_noise_complete.values)\n",
    "        action_pd_no_noise_nan_mask = np.isnan(action_pd_no_noise_complete.values) & ~np.isnan(action_pd_noise_complete.values)\n",
    "    \n",
    "        merge = pd.merge(action_pd_no_noise_complete, action_pd_noise_complete, how='outer')[all_columns]\n",
    "        a = abs(merge.iloc[:4,:].to_numpy() - merge.iloc[4:,:].to_numpy())\n",
    "        a[common_nan_mask] = 0\n",
    "        min = np.nanmin(a) - 1\n",
    "        max = np.nanmax(a) + 1\n",
    "        print(f\"min: {min}, max: {max}\")\n",
    "        print(np.any(action_pd_noise_nan_mask == True))\n",
    "        print(np.any(action_pd_no_noise_nan_mask == True))\n",
    "        if np.any(action_pd_noise_nan_mask == True):\n",
    "            a[action_pd_noise_nan_mask] = np.nanmax(a) + 2\n",
    "        if np.any(action_pd_no_noise_nan_mask == True):\n",
    "            a[action_pd_no_noise_nan_mask] = np.nanmin(a) - 2\n",
    "        # VISUALIZE TERMINAL STATES\n",
    "        a[masked_data_terminal.mask] = np.nan\n",
    "        plt.imshow(a, aspect=\"auto\", cmap=cmap, vmin=min, vmax=max)\n",
    "        plt.colorbar()\n",
    "    \n",
    "        print(f\"name: {name[agent][exploration_strategy][somegrid][someghost][somenoise][idxs[sortex_idx]]}\")\n",
    "        if not os.path.exists(f\"{folder}/{subfolder}\"):\n",
    "            os.makedirs(f\"{folder}/{subfolder}\")\n",
    "        plt.savefig(f\"{folder}/{subfolder}/{name[agent][exploration_strategy][somegrid][someghost][somenoise][idxs[sortex_idx]]}.png\")\n",
    "        plt.show()\n",
    "\n",
    "# generate GIFS\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "def create_gif(input_folder, output_file, file_extension=\".png\", duration=1.0):\n",
    "    images = []\n",
    "\n",
    "    # Get file names and sort them based on the number of epochs\n",
    "    idxs = sorted(range(len(name[agent][exploration_strategy][somegrid][someghost][somenoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someghost][somenoise][x].split('_')[-2]))\n",
    "    for filename in np.asarray(name[agent][exploration_strategy][somegrid][someghost][somenoise])[idxs]:\n",
    "        filepath = os.path.join(input_folder, filename + \".png\")\n",
    "        images.append(imageio.imread(filepath))\n",
    "\n",
    "    # Save the images as a GIF with the specified duration\n",
    "    imageio.mimsave(output_file, images, duration=duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON SEMANTIC NOISE\n",
    "#grid\n",
    "somegrid_l = ['v2','v3','v4']\n",
    "\n",
    "someagent_l = ['SarsaAgent']\n",
    "someexploration_strategy_l = ['Boltzmann']\n",
    "#training env\n",
    "someghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}','DirectionalGhost_{\"index\":1,\"prob\":0.3}','DirectionalGhost_{\"index\":1,\"prob\":0.6}']\n",
    "somenoise_l = ['{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}']\n",
    "#testing env\n",
    "someotherghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}','DirectionalGhost_{\"index\":1,\"prob\":0.3}','DirectionalGhost_{\"index\":1,\"prob\":0.6}']\n",
    "someothernoise_l = ['{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}']\n",
    "idxs=0\n",
    "\n",
    "for someagent in someagent_l:\n",
    "    for someexploration_strategy in someexploration_strategy_l:\n",
    "        for somegrid in somegrid_l:\n",
    "            for someghost, somenoise, someotherghost, someothernoise in zip(someghost_l, somenoise_l, someotherghost_l, someothernoise_l):\n",
    "                folder = f'_trial_learnability_{someagent}_{someexploration_strategy}_' + re.sub(r\"_training_agent_\\d+_epoch\", \"\", np.asarray(name[agent][exploration_strategy][somegrid][someghost][somenoise])[0])\n",
    "                output_name = re.sub(r\"_training_agent_\\d+_epoch\", \"\", np.asarray(name[agent][exploration_strategy][somegrid][someghost][noise])[idxs][0])\n",
    "                subfolder = f\"union_{somegrid}_{someghost}_{somenoise}_{someotherghost}_{someothernoise}\"\n",
    "                generategifs_occupancy(folder,subfolder,agent, exploration_strategy,somegrid, someghost, somenoise, someotherghost, someothernoise)\n",
    "                input_folder = f\"{folder}/{subfolder}/\"\n",
    "                output_file = f\"{folder}/{subfolder}/{output_name}.gif\"\n",
    "                create_gif(input_folder, output_file, duration=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEMANTIC NOISE\n",
    "#grid\n",
    "somegrid_l = ['v2','v3','v4']\n",
    "\n",
    "someagent_l = ['SarsaAgent']\n",
    "someexploration_strategy_l = ['Boltzmann']\n",
    "#training env\n",
    "someghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}']\n",
    "somenoise_l = ['{\"mean\":0,\"std\":0}']\n",
    "#testing env\n",
    "someotherghost_l = ['RandomGhostTeleportingNearWalls_{\"index\":1,\"prob\":{}}']\n",
    "someothernoise_l = ['{\"mean\":0,\"std\":0}']\n",
    "\n",
    "for someagent in someagent_l:\n",
    "    for someexploration_strategy in someexploration_strategy_l:\n",
    "        for somegrid in somegrid_l:\n",
    "            for someghost, somenoise, someotherghost, someothernoise in zip(someghost_l, somenoise_l, someotherghost_l, someothernoise_l):\n",
    "                folder = f'_trial_learnability_{someagent}_{someexploration_strategy}_' + re.sub(r\"_training_agent_\\d+_epoch\", \"\", np.asarray(name[agent][exploration_strategy][somegrid][someghost][somenoise])[0])\n",
    "                output_name = re.sub(r\"_training_agent_\\d+_epoch\", \"\", np.asarray(name[agent][exploration_strategy][somegrid][someghost][noise])[idxs][0])\n",
    "                subfolder = f\"union_{somegrid}_{someghost}_{somenoise}_{someotherghost}_{someothernoise}\"\n",
    "                generategifs_occupancy(folder,subfolder,agent, exploration_strategy,somegrid, someghost, somenoise, someotherghost, someothernoise)\n",
    "                input_folder = f\"{folder}/{subfolder}/\"\n",
    "                output_file = f\"{folder}/{subfolder}/{output_name}.gif\"\n",
    "                create_gif(input_folder, output_file, duration=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
