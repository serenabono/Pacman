{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import plotly\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "import plotly.express as px\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                         | 0/156 [00:00<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import csv \n",
    "from tqdm import tqdm\n",
    "\n",
    "data = {}\n",
    "name = {}\n",
    "file_path = ''\n",
    "paths = glob.glob(f'_trial_*{file_path}*')\n",
    "#paths = glob.glob(f'_trial_*')\n",
    "for path in tqdm(paths):\n",
    "    agent = path.split(\"_\")[-6]\n",
    "    exploration_strategy = path.split(\"_\")[-5]\n",
    "    grid = path.split(\"_\")[-4]\n",
    "    ghost = \"_\".join(path.split(\"_\")[-3:-1])\n",
    "    noise = \"\".join(path.split(\"_\")[-1])\n",
    "    pkl_files = glob.glob(os.path.join(path, 'saved_agent*.pkl'))\n",
    "    for file in pkl_files:       \n",
    "        if \"learnability\" in path:\n",
    "            otherghost = ghost\n",
    "            othernoise = noise\n",
    "        else:\n",
    "            repeat_grid = file.split(\"_\")[3]\n",
    "            path_file = f\"_{repeat_grid}\" + re.findall(r'-train.*?_end', file)[0]\n",
    "            path_file = path_file.replace(\"'\",\"\\\"\").replace(\" \", \"\").replace(\"-train\",\"\").replace(\"-test\",\"\").replace(\"_end\", \"\")\n",
    "            otherghost = \"_\".join(path_file.split(\"_\")[2:4])\n",
    "            othernoise = path_file.split(\"_\")[4]\n",
    "            \n",
    "        if agent not in data:\n",
    "            data[agent] = {}\n",
    "            name[agent] = {}\n",
    "        if exploration_strategy not in data[agent]:\n",
    "            data[agent][exploration_strategy] = {}\n",
    "            name[agent][exploration_strategy] = {}\n",
    "        if grid not in data[agent][exploration_strategy]:\n",
    "            data[agent][exploration_strategy][grid] = {}\n",
    "            name[agent][exploration_strategy][grid] = {}\n",
    "        if ghost not in data[agent][exploration_strategy][grid]:\n",
    "            data[agent][exploration_strategy][grid][ghost] = {}\n",
    "            name[agent][exploration_strategy][grid][ghost] = {}\n",
    "        if noise not in data[agent][exploration_strategy][grid][ghost]:\n",
    "            data[agent][exploration_strategy][grid][ghost][noise] = {}\n",
    "            name[agent][exploration_strategy][grid][ghost][noise] = {}\n",
    "        if otherghost not in data[agent][exploration_strategy][grid][ghost][noise]:\n",
    "            data[agent][exploration_strategy][grid][ghost][noise][otherghost] = {}\n",
    "            name[agent][exploration_strategy][grid][ghost][noise][otherghost] = {}\n",
    "        if othernoise not in data[agent][exploration_strategy][grid][ghost][noise][otherghost]:\n",
    "            name[agent][exploration_strategy][grid][ghost][noise][otherghost][othernoise] = []\n",
    "            data[agent][exploration_strategy][grid][ghost][noise][otherghost][othernoise] = {}\n",
    "            data[agent][exploration_strategy][grid][ghost][noise][otherghost][othernoise][\"tables\"] = []\n",
    "    \n",
    "        values = []\n",
    "        with open(file, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter='\\n', quotechar='|')\n",
    "            for row in reader:\n",
    "                values.append(float(row[0]))\n",
    "        data[agent][exploration_strategy][grid][ghost][noise][otherghost][othernoise][\"values\"] = values\n",
    "    \n",
    "        json_files = glob.glob(os.path.join(path, '*epoch.json')) \n",
    "        for file in json_files:\n",
    "            with open(file) as f:\n",
    "                train_epoch = file.split(\"-\")[-1].replace(rf\"train0_\",\"\").replace(\".json\",\"\")\n",
    "                data[agent][exploration_strategy][grid][ghost][noise][otherghost][othernoise][\"tables\"].append(json.load(f))\n",
    "                name[agent][exploration_strategy][grid][ghost][noise][otherghost][othernoise].append(f'{re.sub(\"./_trial_\", \"\", path)}_{train_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "def generate_occupancy(folder,subfolder,agent, exploration_strategy, somegrid, someghost, somenoise, someotherghost, someothernoise, sortex_idx):\n",
    "    \n",
    "    states_distribution = {}\n",
    "    if agent not in states_distribution:\n",
    "        states_distribution[agent] = {}\n",
    "    if exploration_strategy not in states_distribution[agent]:\n",
    "        states_distribution[agent][exploration_strategy] = {}\n",
    "    if somegrid not in states_distribution[agent][exploration_strategy]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid] = {}\n",
    "    if someghost not in states_distribution[agent][exploration_strategy][somegrid]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][someghost] = {}\n",
    "    if somenoise not in states_distribution[agent][exploration_strategy][somegrid][someghost]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][someghost][somenoise] = {}\n",
    "    if someotherghost not in states_distribution[agent][exploration_strategy][somegrid][someghost][somenoise]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][someghost][somenoise][someotherghost] = {}\n",
    "    if someothernoise not in states_distribution[agent][exploration_strategy][somegrid][someghost][somenoise][someotherghost]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][someghost][somenoise][someotherghost][someothernoise] = {}\n",
    "        \n",
    "    idxs = sorted(range(len(name[agent][exploration_strategy][somegrid][someghost][somenoise][someghost][somenoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someghost][somenoise][someghost][somenoise][x].split('_')[-2]))\n",
    "    evolution_game = np.asarray(data[agent][exploration_strategy][somegrid][someghost][somenoise][someghost][somenoise][\"tables\"])[idxs]\n",
    "    idxs_o = sorted(range(len(name[agent][exploration_strategy][somegrid][someotherghost][someothernoise][someotherghost][someothernoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someotherghost][someothernoise][someotherghost][someothernoise][x].split('_')[-2]))\n",
    "    evolution_game_other = np.asarray(data[agent][exploration_strategy][somegrid][someotherghost][someothernoise][someotherghost][someothernoise][\"tables\"])[idxs_o]\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[-1]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[-1]).sort_index()\n",
    "    all_columns = pd.merge(action_pd_no_noise.fillna(np.nan).astype(float), action_pd_noise.fillna(np.nan).astype(float), how=\"outer\").columns\n",
    "    action_pd_no_noise_complete = pd.concat([action_pd_no_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_no_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    action_pd_noise_complete = pd.concat([action_pd_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    common_nan_mask = np.isnan(action_pd_no_noise_complete.values) & np.isnan(action_pd_noise_complete.values)\n",
    "    column_mask = np.all(common_nan_mask, axis=0)\n",
    "    masked_data_terminal = np.ma.masked_array(common_nan_mask, mask=np.repeat(column_mask.reshape(1,-1), 4, axis=0))\n",
    "    \n",
    "    #for sortex_idx in range(len(data[agent][exploration_strategy][somegrid][someghost][somenoise][someghost][somenoise][\"values\"])):\n",
    "    #fig, ax = plt.subplots(1,1, figsize=(27,27))\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[sortex_idx]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[sortex_idx]).sort_index()\n",
    "\n",
    "    action_pd_no_noise_complete = pd.concat([action_pd_no_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_no_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    action_pd_noise_complete = pd.concat([action_pd_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    common_nan_mask = np.isnan(action_pd_no_noise_complete.values) & np.isnan(action_pd_noise_complete.values)\n",
    "    action_pd_noise_nan_mask = np.isnan(action_pd_noise_complete.values) & ~np.isnan(action_pd_no_noise_complete.values)\n",
    "    action_pd_no_noise_nan_mask = np.isnan(action_pd_no_noise_complete.values) & ~np.isnan(action_pd_noise_complete.values)\n",
    "\n",
    "    merge = pd.merge(action_pd_no_noise_complete, action_pd_noise_complete, how='outer')[all_columns]\n",
    "    a = abs(merge.iloc[:4,:].to_numpy() - merge.iloc[4:,:].to_numpy())\n",
    "    \n",
    "    if np.any(action_pd_noise_nan_mask == True):\n",
    "        reds = np.sum(action_pd_noise_nan_mask)\n",
    "    else:\n",
    "        reds = 0\n",
    "    if np.any(action_pd_no_noise_nan_mask == True):\n",
    "        blues = np.sum(action_pd_no_noise_nan_mask)\n",
    "    else:\n",
    "        blues = 0\n",
    "    greens = np.sum(masked_data_terminal.mask)\n",
    "    states = np.sum(~common_nan_mask) - reds - blues\n",
    "    G = data[agent][exploration_strategy][somegrid][someghost][somenoise][someotherghost][someothernoise][\"values\"][sortex_idx]\n",
    "    L = data[agent][exploration_strategy][somegrid][someotherghost][someothernoise][someotherghost][someothernoise][\"values\"][sortex_idx]\n",
    "    \n",
    "    return [reds, blues, states]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanargmax_with_default(series):\n",
    "    return 0 if series.isna().all() else np.nanargmax(series)\n",
    "\n",
    "def generate_inner_explored_states(folder, subfolder, agent, exploration_strategy, somegrid, someghost, somenoise, someotherghost, someothernoise, sortex_idx):\n",
    "    \n",
    "    states_distribution = {}\n",
    "    if agent not in states_distribution:\n",
    "        states_distribution[agent] = {}\n",
    "    if exploration_strategy not in states_distribution[agent]:\n",
    "        states_distribution[agent][exploration_strategy] = {}\n",
    "    if somegrid not in states_distribution[agent][exploration_strategy]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid] = {}\n",
    "    if someghost not in states_distribution[agent][exploration_strategy][somegrid]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][someghost] = {}\n",
    "    if somenoise not in states_distribution[agent][exploration_strategy][somegrid][someghost]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][someghost][somenoise] = {}\n",
    "    if someotherghost not in states_distribution[agent][exploration_strategy][somegrid][someghost][somenoise]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][someghost][somenoise][someotherghost] = {}\n",
    "    if someothernoise not in states_distribution[agent][exploration_strategy][somegrid][someghost][somenoise][someotherghost]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][someghost][somenoise][someotherghost][someothernoise] = {}\n",
    "        \n",
    "    idxs = sorted(range(len(name[agent][exploration_strategy][somegrid][someghost][somenoise][someghost][somenoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someghost][somenoise][someghost][somenoise][x].split('_')[-2]))\n",
    "    evolution_game = np.asarray(data[agent][exploration_strategy][somegrid][someghost][somenoise][someghost][somenoise][\"tables\"])[idxs]\n",
    "    idxs_o = sorted(range(len(name[agent][exploration_strategy][somegrid][someotherghost][someothernoise][someotherghost][someothernoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someotherghost][someothernoise][someotherghost][someothernoise][x].split('_')[-2]))\n",
    "    evolution_game_other = np.asarray(data[agent][exploration_strategy][somegrid][someotherghost][someothernoise][someotherghost][someothernoise][\"tables\"])[idxs_o]\n",
    "\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[-1]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[-1]).sort_index()\n",
    "    all_columns = action_pd_noise.columns.intersection(action_pd_no_noise.columns)\n",
    "    merge_common = pd.concat([action_pd_noise[all_columns], action_pd_no_noise[all_columns]], axis=0, keys=['action_pd_no_noise', 'action_pd_noise'])[all_columns]\n",
    "    merge_common.index = merge_common.index.droplevel()\n",
    "    final_column = np.argsort(merge_common.iloc[:4,:].apply(nanargmax_with_default).to_numpy() == merge_common.iloc[4:,:].apply(nanargmax_with_default).to_numpy())[::-1]\n",
    "    common_nan_mask = np.isnan(merge_common.iloc[:4,:].values) & np.isnan(merge_common.iloc[4:,:].values)\n",
    "    column_mask = np.all(common_nan_mask, axis=0)[final_column]\n",
    "    masked_data_terminal = np.ma.masked_array(common_nan_mask, mask=np.repeat(column_mask.reshape(1,-1), 4, axis=0))\n",
    "    all_columns = all_columns[final_column]\n",
    "    directory_path = f\"{folder}/{subfolder}\"\n",
    "\n",
    "    #for sortex_idx in range(len(data[agent][exploration_strategy][somegrid][someghost][somenoise][someghost][somenoise][\"values\"])):\n",
    "\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[sortex_idx]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[sortex_idx]).sort_index()\n",
    "\n",
    "    common_columns = action_pd_no_noise.columns.intersection(action_pd_noise.columns)\n",
    "    action_pd_no_noise_common = pd.concat([action_pd_no_noise[common_columns],pd.DataFrame(columns=list(set(all_columns) - set(common_columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    action_pd_noise_common = pd.concat([action_pd_noise[common_columns],pd.DataFrame(columns=list(set(all_columns) - set(common_columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "\n",
    "    merge_common = pd.concat([action_pd_no_noise_common, action_pd_noise_common], axis=0, keys=['action_pd_no_noise', 'action_pd_noise'])[all_columns]\n",
    "    a = pd.DataFrame(merge_common.iloc[:4,:].apply(nanargmax_with_default).to_numpy() == merge_common.iloc[4:,:].apply(nanargmax_with_default).to_numpy(), index=all_columns).values.astype(float)\n",
    "    states = a.shape[0]\n",
    "    common = states - np.sum(a)\n",
    "    perc_common = common/states\n",
    "    G = data[agent][exploration_strategy][somegrid][someghost][somenoise][someotherghost][someothernoise][\"values\"][sortex_idx]\n",
    "    L = data[agent][exploration_strategy][somegrid][someotherghost][someothernoise][someotherghost][someothernoise][\"values\"][sortex_idx]\n",
    "    states_distribution[agent][exploration_strategy][somegrid][someghost][somenoise][someotherghost][someothernoise][sortex_idx] = [perc_common, L, G]     \n",
    "    return [perc_common, L, G]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# NON SEMANTIC NOISE\n",
    "somegrid_l = ['v2','v3', 'v4']\n",
    "someagent_l = ['BoltzmannAgent','SarsaAgent']\n",
    "someexploration_strategy_l = ['Boltzmann','Egreedy']\n",
    "#training env\n",
    "someghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}','DirectionalGhost_{\"index\":1,\"prob\":0.3}','DirectionalGhost_{\"index\":1,\"prob\":0.6}'] \n",
    "somenoise_l = ['{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}']\n",
    "#testing env\n",
    "someotherghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}','DirectionalGhost_{\"index\":1,\"prob\":0.3}','DirectionalGhost_{\"index\":1,\"prob\":0.6}']\n",
    "someothernoise_l = ['{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEMANTIC NOISE\n",
    "somegrid_l = ['v2','v3', 'v4']\n",
    "someagent_l = ['SarsaAgent','BoltzmannAgent']\n",
    "someexploration_strategy_l = ['Boltzmann','Egreedy']\n",
    "#training env\n",
    "someghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}']\n",
    "somenoise_l = ['{\"mean\":0,\"std\":0}']\n",
    "#testing env\n",
    "someotherghost_l = ['RandomGhostTeleportingNearWalls_{\"index\":1,\"prob\":{}}']\n",
    "someothernoise_l =  ['{\"mean\":0,\"std\":0}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'somegrid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data[agent][exploration_strategy][\u001b[43msomegrid\u001b[49m][someghost][somenoise]\u001b[38;5;241m.\u001b[39mkeys()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'somegrid' is not defined"
     ]
    }
   ],
   "source": [
    "data[agent][exploration_strategy][somegrid][someghost][somenoise].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[503, 417, 186, 0.13941018766756033, -303.6, -507.1000061035156]\n",
      "[396, 736, 293, 0.2225201072386059, -505.8, -407.1000061035156]\n",
      "[417, 819, 477, 0.3297587131367292, -308.1, -505.79998779296875]\n",
      "[354, 923, 540, 0.36193029490616624, -209.8, -311.29998779296875]\n",
      "[361, 937, 605, 0.4075067024128686, -205.5, -506.79998779296875]\n",
      "[335, 995, 631, 0.4343163538873995, -517.1, -317.20001220703125]\n",
      "[319, 1002, 686, 0.4959785522788204, -205.9, -512.4000244140625]\n",
      "[295, 1021, 710, 0.4959785522788204, -201.8, -417.1000061035156]\n",
      "[270, 1020, 753, 0.5201072386058981, -303.3, 92.0]\n",
      "[265, 1024, 758, 0.5415549597855228, -303.7, -102.19999694824219]\n",
      "[257, 1032, 781, 0.5361930294906166, -208.9, -111.80000305175781]\n",
      "[254, 1050, 784, 0.5361930294906166, -217.1, -200.89999389648438]\n",
      "[253, 1044, 797, 0.5683646112600537, -305.5, 92.9000015258789]\n",
      "[251, 1061, 799, 0.579088471849866, -202.7, -4.300000190734863]\n",
      "[254, 1070, 805, 0.5951742627345844, -7.6, 95.19999694824219]\n",
      "[252, 1071, 807, 0.6005361930294906, -108.1, -10.100000381469727]\n",
      "[252, 1066, 818, 0.6112600536193029, -205.2, -206.3000030517578]\n",
      "[250, 1067, 820, 0.6058981233243967, 97.7, -1.600000023841858]\n",
      "[256, 1069, 820, 0.6246648793565683, -106.8, -100.0]\n",
      "[256, 1069, 820, 0.6193029490616622, -107.1, -205.5]\n",
      "[256, 1069, 820, 0.6112600536193029, -102.1, 296.8999938964844]\n",
      "[256, 1069, 820, 0.6166219839142091, -8.0, 201.1999969482422]\n",
      "[256, 1069, 820, 0.6327077747989276, 181.7, 100.5]\n",
      "[256, 1069, 820, 0.6300268096514745, -6.3, 95.4000015258789]\n",
      "[256, 1072, 820, 0.613941018766756, 194.1, 304.79998779296875]\n",
      "[256, 1072, 820, 0.6005361930294906, 188.3, 94.9000015258789]\n",
      "[254, 1070, 825, 0.6166219839142091, 93.3, 198.60000610351562]\n",
      "[254, 1070, 825, 0.6166219839142091, 403.3, -103.69999694824219]\n",
      "[254, 1070, 825, 0.5978552278820375, 294.1, -94.80000305175781]\n",
      "[252, 1071, 827, 0.5898123324396782, 0.7, 300.20001220703125]\n",
      "[252, 1071, 827, 0.5871313672922251, 199.3, 305.8999938964844]\n",
      "[252, 1071, 827, 0.5764075067024129, 303.8, 106.4000015258789]\n",
      "[252, 1071, 827, 0.579088471849866, 401.8, 202.10000610351562]\n",
      "[252, 1071, 827, 0.579088471849866, 299.5, 202.89999389648438]\n",
      "[252, 1071, 827, 0.5737265415549598, 398.1, 107.0999984741211]\n",
      "[252, 1071, 827, 0.5576407506702413, 194.9, 401.5]\n",
      "[252, 1071, 827, 0.5495978552278821, 307.3, 305.3999938964844]\n",
      "[252, 1071, 827, 0.5603217158176944, 305.5, 205.1999969482422]\n",
      "[252, 1071, 827, 0.5630026809651475, 408.4, 305.1000061035156]\n",
      "[252, 1071, 827, 0.5656836461126006, 303.6, 510.3999938964844]\n",
      "[252, 1071, 827, 0.5415549597855228, 408.8, -96.80000305175781]\n",
      "[252, 1071, 827, 0.546916890080429, 298.4, 107.0999984741211]\n",
      "[252, 1071, 827, 0.5549597855227882, 97.5, 105.30000305175781]\n",
      "[252, 1071, 827, 0.5549597855227882, 306.6, 408.6000061035156]\n",
      "[252, 1071, 827, 0.5603217158176944, 405.6, 408.6000061035156]\n",
      "[252, 1071, 827, 0.5630026809651475, 101.6, 309.1000061035156]\n",
      "[252, 1071, 827, 0.5361930294906166, 100.3, 105.30000305175781]\n",
      "[252, 1071, 827, 0.5361930294906166, 401.5, 306.8999938964844]\n",
      "[252, 1071, 827, 0.5335120643431636, 203.2, -96.19999694824219]\n",
      "[252, 1071, 827, 0.5361930294906166, 304.0, 304.29998779296875]\n",
      "[252, 1071, 827, 0.5201072386058981, 204.6, 206.39999389648438]\n",
      "[252, 1071, 827, 0.5201072386058981, 304.6, 98.4000015258789]\n",
      "[252, 1071, 827, 0.5281501340482574, 506.8, 303.20001220703125]\n",
      "[252, 1071, 827, 0.5388739946380697, 300.8, 406.1000061035156]\n",
      "[252, 1071, 827, 0.5227882037533512, 206.4, 203.3000030517578]\n",
      "[252, 1071, 827, 0.5227882037533512, 404.2, 309.0]\n",
      "[252, 1071, 827, 0.514745308310992, 106.0, 407.1000061035156]\n",
      "[252, 1071, 827, 0.5201072386058981, 102.8, 208.1999969482422]\n",
      "[252, 1071, 827, 0.5093833780160858, 405.1, 306.8999938964844]\n",
      "[252, 1071, 827, 0.517426273458445, 506.6, 207.8000030517578]\n",
      "[252, 1071, 827, 0.5335120643431636, 305.5, 404.6000061035156]\n",
      "[252, 1071, 827, 0.5335120643431636, 408.2, 206.3000030517578]\n",
      "[252, 1071, 827, 0.5388739946380697, 403.9, 512.0]\n",
      "[252, 1071, 827, 0.5308310991957105, 406.3, 410.20001220703125]\n",
      "[252, 1071, 827, 0.5254691689008043, 308.3, 306.70001220703125]\n",
      "[238, 1435, 841, 0.5335120643431636, -13.0, 404.20001220703125]\n",
      "[218, 1777, 861, 0.546916890080429, -309.2, 308.79998779296875]\n",
      "[214, 1972, 865, 0.5549597855227882, 191.7, 302.0]\n",
      "[214, 1976, 865, 0.5549597855227882, 507.8, 307.6000061035156]\n",
      "[214, 1976, 865, 0.5495978552278821, 307.5, 305.79998779296875]\n",
      "[214, 1976, 865, 0.5549597855227882, 409.8, 406.5]\n",
      "[214, 1976, 865, 0.5549597855227882, 409.6, 306.1000061035156]\n",
      "[214, 1976, 865, 0.5495978552278821, 306.2, 410.6000061035156]\n",
      "[214, 1976, 865, 0.5656836461126006, 307.3, 407.8999938964844]\n",
      "[214, 1976, 865, 0.5764075067024129, 508.2, 208.39999389648438]\n",
      "[214, 1976, 865, 0.5710455764075067, 407.6, 209.39999389648438]\n",
      "[214, 1976, 865, 0.5764075067024129, 408.6, 199.5]\n",
      "[214, 2041, 865, 0.579088471849866, -204.8, 105.69999694824219]\n",
      "[214, 2204, 865, 0.5710455764075067, 99.9, 307.8999938964844]\n",
      "[210, 2224, 869, 0.5710455764075067, 201.4, 307.20001220703125]\n",
      "[202, 2305, 877, 0.5630026809651475, 93.6, 101.9000015258789]\n",
      "[196, 2471, 883, 0.5603217158176944, 192.9, -101.0999984741211]\n",
      "[188, 2609, 891, 0.5683646112600537, 193.8, 302.29998779296875]\n",
      "[186, 2644, 893, 0.5630026809651475, 98.5, 207.1999969482422]\n",
      "[177, 2758, 902, 0.5764075067024129, 297.4, 309.1000061035156]\n",
      "[177, 2933, 902, 0.5817694369973191, 402.8, 307.20001220703125]\n",
      "[177, 3020, 902, 0.579088471849866, 300.5, 410.29998779296875]\n",
      "[175, 3137, 904, 0.579088471849866, 95.5, 6.099999904632568]\n",
      "[175, 3178, 904, 0.579088471849866, 507.4, 404.79998779296875]\n",
      "[171, 3239, 908, 0.5764075067024129, 99.1, 300.1000061035156]\n",
      "[171, 3314, 908, 0.5924932975871313, 400.8, 207.6999969482422]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for someagent in someagent_l:\n",
    "    if someagent not in name:\n",
    "        continue\n",
    "    for someexploration_strategy in someexploration_strategy_l:\n",
    "        if someexploration_strategy not in name[someagent]:\n",
    "            continue\n",
    "        for somegrid in somegrid_l:\n",
    "            if somegrid not in name[someagent][someexploration_strategy]:\n",
    "                continue\n",
    "            for someghost, somenoise, someotherghost, someothernoise in zip(someghost_l, somenoise_l, someotherghost_l, someothernoise_l):\n",
    "                if someghost not in name[someagent][someexploration_strategy][somegrid]:\n",
    "                    continue\n",
    "                if somenoise not in name[someagent][someexploration_strategy][somegrid][someghost]:\n",
    "                    continue\n",
    "                input_string = np.asarray(name[agent][exploration_strategy][somegrid][someghost][somenoise][someghost][somenoise])[0]\n",
    "                folder = re.sub(r\"_training_agent_\\d+_epoch\", \"\", input_string)\n",
    "                subfolder = f\"results_{somegrid}_{someghost}_{somenoise}_{someotherghost}_{someothernoise}\"\n",
    "                output_name = re.sub(\"results_\",\"\",subfolder)\n",
    "                pickle_file_path = f\"{folder}/{subfolder}.pkl\"\n",
    "                values = []\n",
    "                for sortex_idx in range(len(data[agent][exploration_strategy][somegrid][someghost][somenoise][someghost][somenoise][\"values\"])):\n",
    "                    a = generate_inner_explored_states(folder,subfolder,someagent, someexploration_strategy, somegrid, someghost, somenoise, someotherghost, someothernoise, sortex_idx)\n",
    "                    b = generate_occupancy(folder,subfolder,agent, exploration_strategy,somegrid, someghost, somenoise, someotherghost, someothernoise, sortex_idx)\n",
    "                    values.append(b + a)\n",
    "                    print(b + a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 156/156 [00:01<00:00, 85.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import csv \n",
    "from tqdm import tqdm\n",
    "\n",
    "data = {}\n",
    "name = {}\n",
    "file_path = ''\n",
    "paths = glob.glob(f'_trial_*{file_path}*')\n",
    "#paths = glob.glob(f'_trial_*')\n",
    "for path in tqdm(paths):\n",
    "    agent = path.split(\"_\")[-6]\n",
    "    exploration_strategy = path.split(\"_\")[-5]\n",
    "    grid = path.split(\"_\")[-4]\n",
    "    ghost = \"_\".join(path.split(\"_\")[-3:-1])\n",
    "    noise = \"\".join(path.split(\"_\")[-1])\n",
    "    pkl_files = glob.glob(os.path.join(path, 'saved_agent*.pkl'))\n",
    "    for file in pkl_files:       \n",
    "        if \"learnability\" in path:\n",
    "            otherghost = ghost\n",
    "            othernoise = noise\n",
    "        else:\n",
    "            repeat_grid = file.split(\"_\")[3]\n",
    "            path_file = f\"_{repeat_grid}\" + re.findall(r'-train.*?_end', file)[0]\n",
    "            path_file = path_file.replace(\"'\",\"\\\"\").replace(\" \", \"\").replace(\"-train\",\"\").replace(\"-test\",\"\").replace(\"_end\", \"\")\n",
    "            otherghost = \"_\".join(path_file.split(\"_\")[2:4])\n",
    "            othernoise = path_file.split(\"_\")[4]\n",
    "            \n",
    "        if agent not in data:\n",
    "            data[agent] = {}\n",
    "            name[agent] = {}\n",
    "        if exploration_strategy not in data[agent]:\n",
    "            data[agent][exploration_strategy] = {}\n",
    "            name[agent][exploration_strategy] = {}\n",
    "        if grid not in data[agent][exploration_strategy]:\n",
    "            data[agent][exploration_strategy][grid] = {}\n",
    "            name[agent][exploration_strategy][grid] = {}\n",
    "        if ghost not in data[agent][exploration_strategy][grid]:\n",
    "            data[agent][exploration_strategy][grid][ghost] = {}\n",
    "            name[agent][exploration_strategy][grid][ghost] = {}\n",
    "        if noise not in data[agent][exploration_strategy][grid][ghost]:\n",
    "            data[agent][exploration_strategy][grid][ghost][noise] = {}\n",
    "            name[agent][exploration_strategy][grid][ghost][noise] = {}\n",
    "        if otherghost not in data[agent][exploration_strategy][grid][ghost][noise]:\n",
    "            data[agent][exploration_strategy][grid][ghost][noise][otherghost] = {}\n",
    "            name[agent][exploration_strategy][grid][ghost][noise][otherghost] = {}\n",
    "        if othernoise not in data[agent][exploration_strategy][grid][ghost][noise][otherghost]:\n",
    "            name[agent][exploration_strategy][grid][ghost][noise][otherghost][othernoise] = []\n",
    "            data[agent][exploration_strategy][grid][ghost][noise][otherghost][othernoise] = {}\n",
    "            data[agent][exploration_strategy][grid][ghost][noise][otherghost][othernoise][\"tables\"] = []\n",
    "    \n",
    "        values = []\n",
    "        with open(file, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter='\\n', quotechar='|')\n",
    "            for row in reader:\n",
    "                values.append(float(row[0]))\n",
    "        data[agent][exploration_strategy][grid][ghost][noise][otherghost][othernoise][\"values\"] = values\n",
    "    \n",
    "        json_files = glob.glob(os.path.join(path, '*epoch.json')) \n",
    "        for file in json_files:\n",
    "            train_epoch = file.split(\"-\")[-1].replace(rf\"train0_\",\"\").replace(\".json\",\"\")\n",
    "            name[agent][exploration_strategy][grid][ghost][noise][otherghost][othernoise].append(f'{re.sub(\"./_trial_\", \"\", path)}_{train_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DirectionalGhost_{\"index\":1,\"prob\":0.6}', 'RandomGhost_{\"index\":1,\"prob\":{}}', 'RandomGhostTeleportingNearWalls_{\"index\":1,\"prob\":{}}', 'DirectionalGhost_{\"index\":1,\"prob\":0.3}'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name['BoltzmannAgent']['Boltzmann']['v2'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "def test_significance(x,y):\n",
    "    return scipy.stats.wilcoxon(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# NON SEMANTIC NOISE\n",
    "somegrid_l = ['v2','v3','v4']\n",
    "normalization_factors_l = [982, 466, 626]\n",
    "someagent_l = ['BoltzmannAgent','SarsaAgent']\n",
    "someexploration_strategy_l = ['Boltzmann','Egreedy']\n",
    "#training env\n",
    "someghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}','DirectionalGhost_{\"index\":1,\"prob\":0.3}','DirectionalGhost_{\"index\":1,\"prob\":0.6}','RandomGhost_{\"index\":1,\"prob\":{}}'] \n",
    "somenoise_l = ['{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}']\n",
    "#testing env\n",
    "someotherghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}','DirectionalGhost_{\"index\":1,\"prob\":0.3}','DirectionalGhost_{\"index\":1,\"prob\":0.6}','RandomGhostTeleportingNearWalls_{\"index\":1,\"prob\":{}}']\n",
    "someothernoise_l = ['{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# SEMANTIC NOISE\n",
    "somegrid_l = ['v2','v3','v4']\n",
    "normalization_factors_l = [982, 466, 626]\n",
    "someagent_l = ['BoltzmannAgent','SarsaAgent']\n",
    "someexploration_strategy_l = ['Boltzmann','Egreedy']\n",
    "#training env\n",
    "someghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}'] \n",
    "somenoise_l = ['{\"mean\":0,\"std\":0}']\n",
    "#testing env\n",
    "someotherghost_l = ['RandomGhostTeleportingNearWalls_{\"index\":1,\"prob\":{}}']\n",
    "someothernoise_l = ['{\"mean\":0,\"std\":0}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# NON SEMANTIC NOISE\n",
    "somegrid_l = ['v2','v3','v4']\n",
    "normalization_factors_l = [982, 466, 626]\n",
    "\n",
    "someagent_l = ['BoltzmannAgent','SarsaAgent']\n",
    "someexploration_strategy_l = ['Boltzmann','Egreedy']\n",
    "#training env\n",
    "someghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}','DirectionalGhost_{\"index\":1,\"prob\":0.3}','DirectionalGhost_{\"index\":1,\"prob\":0.6}'] \n",
    "somenoise_l = ['{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}']\n",
    "#testing env\n",
    "someotherghost_l = ['RandomGhost_{\"index\":1,\"prob\":{}}','DirectionalGhost_{\"index\":1,\"prob\":0.3}','DirectionalGhost_{\"index\":1,\"prob\":0.6}']\n",
    "someothernoise_l = ['{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_lg = {}\n",
    "contents_lg['blue'] = []\n",
    "contents_lg['red'] = []\n",
    "contents_lg['states'] = []\n",
    "contents_lg['perc_common'] = []\n",
    "gap_lg = []\n",
    "\n",
    "for someagent in someagent_l:\n",
    "    if someagent not in name:\n",
    "        continue\n",
    "    for someexploration_strategy in someexploration_strategy_l:\n",
    "        if someexploration_strategy not in name[someagent]:\n",
    "            continue\n",
    "        for somegrid, norm in zip(somegrid_l, normalization_factors_l):\n",
    "            if somegrid not in name[someagent][someexploration_strategy]:\n",
    "                continue\n",
    "            for someghost, somenoise, someotherghost, someothernoise in zip(someghost_l, somenoise_l, someotherghost_l, someothernoise_l):\n",
    "                if someghost not in name[someagent][someexploration_strategy][somegrid]:\n",
    "                    continue\n",
    "                if somenoise not in name[someagent][someexploration_strategy][somegrid][someghost]:\n",
    "                    continue\n",
    "                input_string = np.asarray(name[agent][exploration_strategy][somegrid][someghost][somenoise][someghost][somenoise])[0]\n",
    "                folder = re.sub(r\"_training_agent_\\d+_epoch\", \"\", input_string)\n",
    "                subfolder = f\"results_{somegrid}_{someghost}_{somenoise}_{someotherghost}_{someothernoise}\"\n",
    "                output_name = re.sub(\"results_\",\"\",subfolder)\n",
    "                file = f\"{folder}/{subfolder}.pkl\"\n",
    "                with open(file, 'rb') as file:\n",
    "                    values = pickle.load(file)\n",
    "                for value in values[-10:]:\n",
    "                    contents_lg['red'].append(value[0]/(norm*4))\n",
    "                    contents_lg['blue'].append(value[1]/(norm*4))\n",
    "                    contents_lg['states'].append(value[2]/(norm*4))\n",
    "                    contents_lg['perc_common'].append(value[3])\n",
    "                    gap_lg.append((value[5] - value[4])/np.abs(value[5]))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sum or Reds and Blues is a good predictor of G>L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-9.48224716568476, pvalue=3.548919764935312e-19, df=358.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_blues_reds = np.array(contents_lg['blue']) + np.array(contents_lg['red'])\n",
    "scipy.stats.ttest_ind(total_blues_reds[np.where(np.array(gap_lg)>0)], total_blues_reds[np.where(np.array(gap_lg)<0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN: 0.08367238081395567 STD: 0.011268688365028584\n",
      "MEAN: 0.27100433401969 STD: 0.01712763227778641\n"
     ]
    }
   ],
   "source": [
    "print( \"MEAN:\", np.mean(total_blues_reds[np.where(np.array(gap_lg)>0)]),\"STD:\", scipy.stats.sem(total_blues_reds[np.where(np.array(gap_lg)>0)])) \n",
    "print( \"MEAN:\", np.mean(total_blues_reds[np.where(np.array(gap_lg)<0)]),\"STD:\",  scipy.stats.sem(total_blues_reds[np.where(np.array(gap_lg)<0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's correlation coefficient: 0.04692360014216373\n",
      "Pearson's p-value: 0.3746992025571309\n",
      "Spearman's correlation coefficient: -0.4222662123833527\n",
      "Spearman's p-value: 5.328027055321341e-17\n"
     ]
    }
   ],
   "source": [
    "# Pearson's correlation test\n",
    "pearson_corr, pearson_p_value = scipy.stats.pearsonr(total_blues_reds, gap_lg)\n",
    "print(f\"Pearson's correlation coefficient: {pearson_corr}\")\n",
    "print(f\"Pearson's p-value: {pearson_p_value}\")\n",
    "\n",
    "# Spearman's correlation test\n",
    "spearman_corr, spearman_p_value = scipy.stats.spearmanr(total_blues_reds, gap_lg)\n",
    "print(f\"Spearman's correlation coefficient: {spearman_corr}\")\n",
    "print(f\"Spearman's p-value: {spearman_p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The % of states that have same preferred action is a good predictor of G>L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-8.7520129662423, pvalue=8.386318852248445e-17, df=358.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_common = np.asarray(contents_lg['perc_common'])\n",
    "scipy.stats.ttest_ind(perc_common[np.where(np.array(gap_lg)>0)], perc_common[np.where(np.array(gap_lg)<0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's correlation coefficient: 0.06367745198930215\n",
      "Pearson's p-value: 0.22811980015776082\n",
      "Spearman's correlation coefficient: -0.25009401155405653\n",
      "Spearman's p-value: 1.5454066617900714e-06\n"
     ]
    }
   ],
   "source": [
    "# Pearson's correlation test\n",
    "pearson_corr, pearson_p_value = scipy.stats.pearsonr(contents_lg['perc_common'], gap_lg)\n",
    "print(f\"Pearson's correlation coefficient: {pearson_corr}\")\n",
    "print(f\"Pearson's p-value: {pearson_p_value}\")\n",
    "\n",
    "# Spearman's correlation test\n",
    "spearman_corr, spearman_p_value = scipy.stats.spearmanr(contents_lg['perc_common'], gap_lg)\n",
    "print(f\"Spearman's correlation coefficient: {spearman_corr}\")\n",
    "print(f\"Spearman's p-value: {spearman_p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
